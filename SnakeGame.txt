Reinforement Learning :-
                                          RL is teaching a software agent how to behave in an environment by telling it how good it's agent

Deep Q Learning :-
                                This approach extends reinforcement learning by using a deep neural network to predict the actions.


Agent:-
--game
--model
Training:
--state = get_state(game)
--action = get_move(state)

    --model.predict()
--reward , game_over , score = game.play_step(action)
--new_state = get_state(game)
--remember
--model.train()


Game(Pygame)
--play_step(action)
      ->reward , game_over , score


Model(PyTorch)
Linear_QNet(DQN)
--model.predict(state)
    ->action



Reward:-
--eat food: +10
--game over : -10
--else: 0


Action:-
[1,0,0] -> Straight
[0,1,0] -> right turn
[0,0,1] -> left turn


State(11 Values):-
[Danger stright , Danger right , Danger left , 
  Dirction left , direction right ,
  Direction up , direction Down,

   Food left , Food right ,
   Food up , Food down
]


(Deep) Q Learning:--
Q Value = Quality of action

0. Init Q Value(= init model)
1. Choose action(model.predict(state))
2. Perform action
3. Measure reward
4. Update Q Value(+ train model)



For Loss Function we use Bellman Equation:

NewQ(s,a) = Q(s,a) + learning rate[R(s,a) + Discount rate maxQ'(s',a') - Q(s,a)]

Q Update Rule Simplified :

Q = model.predict(state0)

Qnew = R + discount rate * max(Q(state1))

Loss function :
loss = (Qnew - Q)^2  (Mean Square Error)


